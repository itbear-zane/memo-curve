import OpenAI from 'openai';
import type { Note } from '../types';

/**
 * Multi-Agent Analysis Service
 * å®ç°å¤šAgentåä½œåˆ†æç¬”è®°çš„åŠŸèƒ½
 */

export interface AgentResponse {
  success: boolean;
  content: string;
  error?: string;
}

export interface IntentAnalysisResult {
  intent: string;
  reviewPassed: boolean;
  attempts: number;
}

/**
 * åˆ›å»ºOpenAIå®¢æˆ·ç«¯
 */
function createClient(config: {
  baseURL: string;
  apiKey: string;
  provider?: string;
  siteUrl?: string;
  siteName?: string;
}): OpenAI {
  const clientConfig: any = {
    baseURL: config.baseURL,
    apiKey: config.apiKey,
    dangerouslyAllowBrowser: true,
  };

  // Add OpenRouter specific headers
  if (config.provider === 'openrouter') {
    clientConfig.defaultHeaders = {};
    if (config.siteUrl) {
      clientConfig.defaultHeaders['HTTP-Referer'] = config.siteUrl;
    }
    if (config.siteName) {
      clientConfig.defaultHeaders['X-Title'] = config.siteName;
    }
  }

  return new OpenAI(clientConfig);
}

/**
 * Agent 1: ç”¨æˆ·æ„å›¾åˆ†æAgent
 */
export async function analyzeUserIntent(
  client: OpenAI,
  model: string,
  userMessageContent: any[],
  onStream?: (content: string) => void
): Promise<string> {
  const intentPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ ç¬”è®°æ„å›¾åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æ‹æ‘„çš„ç¬”è®°ç…§ç‰‡ï¼Œæ‰¾å‡ºç”¨æˆ·çœŸæ­£æƒ³è¦å­¦ä¹ æˆ–çº æ­£çš„é”™é¢˜ã€‚å¦‚æœè¯¥ç¬”è®°æ²¡æœ‰ç…§ç‰‡ï¼Œåˆ™ç›´æ¥è¾“å‡ºåŸæ–‡å³å¯ã€‚

åˆ†æé‡ç‚¹ï¼š
1. å­˜åœ¨ä¸€äº›é¢˜ç›®ç”¨æˆ·å¯èƒ½åšå¯¹äº†ä½†ä¸ç†è§£ï¼Œæ‰€ä»¥ä¼šåœ¨æ—è¾¹è®¢æ­£
2. é”™è¯¯çš„é¢˜ç›®å¦‚æœæœ‰å›¾ç‰‡ï¼Œç”¨æˆ·ä¸€èˆ¬ä¼šç”¨çº¢è‰²æ ‡æ³¨æˆ–åœˆç”»åœ¨æ—è¾¹æ ‡æ³¨æˆ–è®¢æ­£
3. å¦‚æœæ²¡æœ‰å‘ç°æ²¡æœ‰é‡ç‚¹æ ‡æ³¨å°±æŠŠæ‰€æœ‰é¢˜ç›®å‡è§†ä¸ºç”¨æˆ·æ„å›¾é¢˜ç›®
4. å¯¹äºé€‰æ‹©é¢˜ï¼ˆå•é€‰æˆ–å¤šé€‰ï¼‰ï¼Œå¤šé€‰é¢˜å¯èƒ½å­˜åœ¨åŠåšå¯¹ï¼ˆé€‰å¯¹äº†ä½†ä¸å…¨ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- åªéœ€è¾“å‡ºæ‰€æœ‰ç”¨æˆ·æ„å›¾é¢˜ç›®çš„åŸæ–‡
- å¦‚æœåˆ†æä¸å‡ºä»»ä½•é¢˜ç›®ï¼Œåˆ™è¿”å›"æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ„å›¾é¢˜ç›®"
- å¯¹äºå…¬å¼å¿…é¡»ç”¨LaTeXæ ¼å¼
- æ¯é“é¢˜éœ€è¦å•ç‹¬æ ‡æ³¨æ˜¯å•é€‰é¢˜ã€å¤šé€‰é¢˜ã€å¡«ç©ºé¢˜ã€è§£ç­”é¢˜ä¸­çš„å“ªä¸€ç§`;

  const stream = await client.chat.completions.create({
    model,
    messages: [
      {
        role: 'system',
        content: intentPrompt,
      },
      {
        role: 'user',
        content: userMessageContent,
      },
    ],
    temperature: 0.3,
    max_tokens: 1024,
    stream: true,
  });

  let fullContent = '';
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    if (content) {
      fullContent += content;
      onStream?.(fullContent);
    }
  }

  return fullContent;
}

/**
 * Review Agent: å®¡æŸ¥æ„å›¾åˆ†æç»“æœ
 */
export async function reviewIntentAnalysis(
  client: OpenAI,
  model: string,
  intentAnalysis: string,
  userMessageContent: any[],
  onStream?: (content: string) => void
): Promise<{ passed: boolean; feedback: string }> {
  const reviewPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„è´¨é‡å®¡æŸ¥ä¸“å®¶ã€‚ä½ éœ€è¦å®¡æŸ¥å‰ä¸€ä¸ªAgentå¯¹å­¦ä¹ ç¬”è®°æ„å›¾çš„åˆ†ææ˜¯å¦å‡†ç¡®ã€‚

å®¡æŸ¥æ ‡å‡†ï¼š
1. æ˜¯å¦å‡†ç¡®è¯†åˆ«äº†ç”¨æˆ·åšé”™çš„æ‰€æœ‰é¢˜ç›®ï¼ˆä¸èƒ½é—æ¼ï¼Œä¹Ÿä¸èƒ½è¯¯åˆ¤ï¼‰
2. æ˜¯å¦å­˜åœ¨ä¸€äº›ç”¨æˆ·å¯èƒ½åšå¯¹äº†ä½†ä¸ç†è§£çš„é¢˜ç›®æ²¡æœ‰è¢«åˆ†æå‡ºæ¥
4. æ˜¯å¦å­˜åœ¨åŠåšå¯¹çš„å¤šé€‰é¢˜æ²¡æœ‰è¢«åˆ†æå‡ºæ¥
5. æ˜¯å¦æ‰€æœ‰è¾“å‡ºçš„ç”¨æˆ·æ„å›¾é¢˜ç›®éƒ½ä¸åŸæ–‡å®Œå…¨ä¸€è‡´

è¯·å¯¹æ¯”åŸå§‹ç¬”è®°å›¾ç‰‡å’Œæ„å›¾åˆ†æç»“æœï¼Œåˆ¤æ–­åˆ†ææ˜¯å¦å‡†ç¡®ã€‚

è¾“å‡ºæ ¼å¼ï¼š
ç¬¬ä¸€è¡Œå¿…é¡»æ˜¯ï¼šPASS æˆ– FAIL
å¦‚æœæ˜¯FAILï¼Œæ¥ä¸‹æ¥è¯´æ˜é—®é¢˜åœ¨å“ªé‡Œï¼Œéœ€è¦å¦‚ä½•æ”¹è¿›ï¼ˆç®€æ´æ˜ç¡®ï¼Œä¸è¶…è¿‡500å­—ï¼‰
å¦‚æœæ˜¯PASSï¼Œç®€çŸ­è¯´æ˜"åˆ†æå‡†ç¡®"å³å¯`;

  const stream = await client.chat.completions.create({
    model,
    messages: [
      {
        role: 'system',
        content: reviewPrompt,
      },
      {
        role: 'user',
        content: [
          {
            type: 'text',
            text: `åŸå§‹ç¬”è®°å†…å®¹ï¼š`,
          },
          ...userMessageContent,
          {
            type: 'text',
            text: `\n\nå‰ä¸€ä¸ªAgentçš„æ„å›¾åˆ†æç»“æœï¼š\n${intentAnalysis}`,
          },
        ],
      },
    ],
    temperature: 0.2,
    max_tokens: 1024,
    stream: true,
  });

  let reviewResult = '';
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    if (content) {
      reviewResult += content;
      onStream?.(reviewResult);
    }
  }

  const passed = reviewResult.trim().startsWith('PASS');
  const feedback = reviewResult
    .split('\n')
    .slice(1)
    .join('\n')
    .trim();

  return { passed, feedback };
}

/**
 * è¿­ä»£å¼æ„å›¾åˆ†æï¼ˆæœ€å¤š3æ¬¡ï¼‰
 */
export async function analyzeIntentWithReview(
  client: OpenAI,
  model: string,
  userMessageContent: any[],
  onProgress?: (message: string) => void,
  onAgentStream?: (agentId: string, content: string) => void
): Promise<IntentAnalysisResult> {
  const MAX_ATTEMPTS = 3;
  let attempts = 0;
  let intentAnalysis = '';
  let reviewPassed = false;

  while (attempts < MAX_ATTEMPTS && !reviewPassed) {
    attempts++;
    onProgress?.(
      `ğŸ” æ­£åœ¨è¿›è¡Œç¬¬ ${attempts} æ¬¡æ„å›¾åˆ†æ...`
    );

    // Agent 1: åˆ†æç”¨æˆ·æ„å›¾
    intentAnalysis = await analyzeUserIntent(
      client,
      model,
      userMessageContent,
      (content) => onAgentStream?.('intent', content)
    );

    onProgress?.(`ğŸ“‹ æ„å›¾åˆ†æå®Œæˆï¼Œæ­£åœ¨å®¡æŸ¥...`);

    // Review Agent: å®¡æŸ¥åˆ†æç»“æœ
    const review = await reviewIntentAnalysis(
      client,
      model,
      intentAnalysis,
      userMessageContent,
      (content) => onAgentStream?.('review', content)
    );

    reviewPassed = review.passed;

    if (!reviewPassed && attempts < MAX_ATTEMPTS) {
      onProgress?.(
        `âš ï¸ å®¡æŸ¥æœªé€šè¿‡ï¼š${review.feedback}\nå‡†å¤‡é‡æ–°åˆ†æ...`
      );
      // å¦‚æœå®¡æŸ¥æœªé€šè¿‡,å°†åé¦ˆåŠ å…¥åˆ°ä¸‹ä¸€æ¬¡åˆ†æä¸­
      userMessageContent.push({
        type: 'text',
        text: `\n\nã€ä¸Šä¸€æ¬¡åˆ†æçš„é—®é¢˜ã€‘ï¼š${review.feedback}\nè¯·æ ¹æ®ä»¥ä¸Šåé¦ˆé‡æ–°åˆ†æã€‚`,
      });
    } else if (reviewPassed) {
      onProgress?.(`âœ… æ„å›¾å®¡æŸ¥é€šè¿‡`);
    }
  }

  return {
    intent: intentAnalysis,
    reviewPassed,
    attempts,
  };
}

/**
 * Agent 2: åŸå§‹è®°å½•åˆ†æAgent
 */
export async function analyzeOriginalRecord(
  client: OpenAI,
  model: string,
  intent: string,
  userMessageContent: any[],
  onStream?: (content: string) => void
): Promise<string> {
  const prompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é”™é¢˜è¯Šæ–­ä¸“å®¶ã€‚æ ¹æ®å·²ç¡®è®¤çš„ç”¨æˆ·æ„å›¾ï¼Œåˆ†æç”¨æˆ·åœ¨åšé¢˜æ—¶çš„åŸå§‹è®°å½•ã€‚

ç”¨æˆ·æ„å›¾åˆ†æç»“æœï¼š
${intent}

ä½ çš„ä»»åŠ¡ï¼š
1. ä»”ç»†æŸ¥çœ‹ç”¨æˆ·åšé¢˜æ—¶çš„åŸå§‹è®°å½•ï¼ˆæ³¨æ„åŒºåˆ†åŸå§‹è®°å½•å’Œçœ‹ç­”æ¡ˆåçš„è®¢æ­£ï¼‰
2. çº¢è‰²æ ‡æ³¨å¾€å¾€ä¸æ˜¯åŸå§‹è®°å½•
3. æ‰¾å‡ºç”¨æˆ·åœ¨è§£é¢˜è¿‡ç¨‹ä¸­å“ªé‡Œå‡ºé”™äº†
4. åˆ†æé”™è¯¯çš„åŸå› ï¼ˆæ¦‚å¿µç†è§£é”™è¯¯/è®¡ç®—å¤±è¯¯/æ€è·¯åå·®/çŸ¥è¯†ç‚¹é—æ¼ç­‰ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- å¦‚æœæ²¡å‘ç°åŸå§‹è®°å½•ï¼Œå°±ç›´æ¥è¾“å‡ºâ€™æ— åŸå§‹è®°å½•â€˜ï¼Œé™¤æ­¤ä¹‹å¤–ä¸è¦è¾“å‡ºä»»ä½•å†…å®¹
- é’ˆå¯¹æ¯é“é”™é¢˜ï¼Œåªéœ€è¦å…·ä½“æŒ‡å‡ºåŸå§‹è®°å½•ä¸­çš„å†…å®¹å’Œé”™è¯¯æœ¬èº«
- ä¸éœ€è¦ç»™å‡ºåˆ†æè¿‡ç¨‹
- ä¸éœ€è¦è¾“å‡ºä½ è®¤ä¸ºçš„æ­£ç¡®ç­”æ¡ˆ
- ä¸éœ€è¦ç»™å‡ºæ€»ç»“
- ä½¿ç”¨ä¸­æ–‡ï¼Œé€»è¾‘æ¸…æ™°ï¼Œé€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·
- å¯¹äºå…¬å¼å¿…é¡»ç”¨LaTeXæ ¼å¼`;

  const response = await client.chat.completions.create({
    model,
    messages: [
      {
        role: 'system',
        content: prompt,
      },
      {
        role: 'user',
        content: userMessageContent,
      },
    ],
    temperature: 0.4,
    max_tokens: 2048,
    stream: true,
  });

  let fullContent = '';
  for await (const chunk of response) {
    const content = chunk.choices[0]?.delta?.content || '';
    if (content) {
      fullContent += content;
      onStream?.(fullContent);
    }
  }

  return fullContent;
}

/**
 * Agent 3: è®¢æ­£ç­”æ¡ˆåˆ†æAgent
 */
export async function analyzeCorrection(
  client: OpenAI,
  model: string,
  intent: string,
  userMessageContent: any[],
  onStream?: (content: string) => void
): Promise<string> {
  const prompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§£é¢˜æ€è·¯ä¸“å®¶ã€‚æ ¹æ®å·²ç¡®è®¤çš„ç”¨æˆ·æ„å›¾ï¼Œåˆ†æç”¨æˆ·åœ¨é”™é¢˜æ—è¾¹çš„è®¢æ­£ç­”æ¡ˆã€‚

ç”¨æˆ·æ„å›¾åˆ†æç»“æœï¼š
${intent}

ä½ çš„ä»»åŠ¡ï¼š
1. æ‰¾å‡ºç”¨æˆ·åœ¨é”™é¢˜æ—è¾¹è®¢æ­£çš„ç­”æ¡ˆï¼ˆè¿™äº›å¾€å¾€æ˜¯æ­£ç¡®çš„ï¼Œä¸€èˆ¬ç”¨çº¢è‰²ç¬”ä¹¦å†™ï¼‰
2. å¦‚æœæ²¡æ‰¾åˆ°è®¢æ­£ç­”æ¡ˆï¼Œå°±åˆ™ä½ è‡ªå·±åˆ†ææ­£ç¡®çš„è§£é¢˜æ€è·¯å’Œæ­¥éª¤
3. å¦‚æœæœ‰è®¢æ­£çš„ç­”æ¡ˆï¼Œåˆ™æ ¹æ®å…¶åˆ†ææ­£ç¡®çš„è§£é¢˜æ€è·¯å’Œæ­¥éª¤
4. æ³¨æ„è¯†åˆ«æ‰‹å†™å†…å®¹ï¼Œå‡†ç¡®ç†è§£è®¢æ­£çš„é€»è¾‘

è¾“å‡ºè¦æ±‚ï¼š
- å¦‚æœæ²¡æœ‰å‘ç°ä»»ä½•å…·ä½“é¢˜ç›®ï¼Œå°±ç›´æ¥è¾“å‡ºâ€™æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ„å›¾é¢˜ç›®â€˜ï¼Œé™¤æ­¤ä¹‹å¤–ä¸è¦è¾“å‡ºä»»ä½•å†…å®¹
- é’ˆå¯¹æ¯é“é¢˜ï¼Œåªéœ€æ¸…æ™°å±•ç¤ºæ­£ç¡®çš„è§£é¢˜æ€è·¯å’Œç­”æ¡ˆ
- ä¸éœ€è¦ç»™å‡ºæ€»ç»“
- ä½¿ç”¨ä¸­æ–‡ï¼Œæ¡ç†æ¸…æ™°ï¼Œé€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·
- å¯¹äºå…¬å¼å¿…é¡»ç”¨LaTeXæ ¼å¼`;

  const response = await client.chat.completions.create({
    model,
    messages: [
      {
        role: 'system',
        content: prompt,
      },
      {
        role: 'user',
        content: userMessageContent,
      },
    ],
    temperature: 0.4,
    max_tokens: 2048,
    stream: true,
  });

  let fullContent = '';
  for await (const chunk of response) {
    const content = chunk.choices[0]?.delta?.content || '';
    if (content) {
      fullContent += content;
      onStream?.(fullContent);
    }
  }

  return fullContent;
}

/**
 * Agent 4: æ€»ç»“Agent
 */
export async function generateSummary(
  client: OpenAI,
  model: string,
  note: Note,
  intent: string,
  originalAnalysis: string,
  correctionAnalysis: string,
  categoryName: string,
  curveName: string,
  curveIntervals: number[],
  onStream?: (content: string) => void
): Promise<string> {
  const prompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ æŒ‡å¯¼ä¸“å®¶ã€‚åŸºäºå‰é¢å„ä¸ªAgentçš„åˆ†æç»“æœï¼Œä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä¸ªå…¨é¢çš„æ€»ç»“æŠ¥å‘Šã€‚

åˆ†æææ–™ï¼š
1. ç”¨æˆ·æ„å›¾åˆ†æï¼š
${intent}

2. åŸå§‹è®°å½•åˆ†æï¼š
${originalAnalysis}

3. è®¢æ­£ç­”æ¡ˆåˆ†æï¼š
${correctionAnalysis}

ç¬”è®°ä¿¡æ¯ï¼š
- æ ‡é¢˜ï¼š${note.title}
- åˆ†ç±»ï¼š${categoryName}
- é—å¿˜æ›²çº¿ï¼š${curveName} (å¤ä¹ é—´éš”: ${curveIntervals.join(', ')} å¤©)
- åˆ›å»ºæ—¶é—´ï¼š${new Date(note.createdAt).toLocaleDateString('zh-CN')}
- å½“å‰å¤ä¹ é˜¶æ®µï¼šç¬¬${note.stage}æ¬¡å¤ä¹ 
- ä¸‹æ¬¡å¤ä¹ æ—¶é—´ï¼š${new Date(note.nextReviewDate).toLocaleDateString('zh-CN')}

ä½ çš„ä»»åŠ¡ï¼š
1. ä¸€é“ä¸€é“æ€»ç»“è¿™äº›é¢˜ä¸ºä»€ä¹ˆåšé”™äº†
2. æä¾›å¦‚ä½•é¿å…çŠ¯ç±»ä¼¼é”™è¯¯çš„å»ºè®®ï¼Œç®€å•æ˜“æ‡‚å°±å¥½
3. ç®€è¦åˆ†æé¢˜ç›®éš¾åº¦å’Œå‡ºç°é¢‘ç‡ï¼Œç»™å‡ºé’ˆå¯¹æ€§å»ºè®®ï¼š
   - å¦‚æœé¢˜ç›®å¾ˆéš¾ã€æ¯”è¾ƒå°ä¼—ï¼šå‘Šè¯‰ç”¨æˆ·ä¸ç”¨ç€æ€¥
   - å¦‚æœé¢˜ç›®ç®€å•ã€é«˜é¢‘å‡ºç°ï¼šæé†’ç”¨æˆ·ç€é‡æ³¨æ„ï¼Œåº”è¯¥ç»å¸¸å¤ä¹ 
4. é’ˆå¯¹é—å¿˜æ›²çº¿å’Œå½“å‰å¤ä¹ æ¬¡æ•°ï¼š
   - å¦‚æœå·²ç»è¿‡æœŸï¼šç»™å‡ºä¸€äº›å‹åŠ›çš„è¯ï¼ˆè¯­æ°”ç¨é‡ï¼‰
   - å¦‚æœæœªè¿‡æœŸï¼šåŠ ç²—æé†’ä¸‹æ¬¡å¤ä¹ æ—¶é—´ï¼ˆç®€æ´ï¼‰
   - 'ç¬¬0æ¬¡å¤ä¹ 'æ„å‘³ç€ä»Šå¤©åˆšæ·»åŠ ï¼Œä¸éœ€è¦å¼ºè°ƒ
5. å¦‚æœå‘ç°æ²¡æœ‰åŸå§‹è®°å½•æˆ–è®¢æ­£ç­”æ¡ˆï¼Œå°±ç›´æ¥è¾“å‡º'æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ„å›¾é¢˜ç›®'ï¼Œé™¤æ­¤ä¹‹å¤–ä¸è¦è¾“å‡ºä»»ä½•å†…å®¹

è¾“å‡ºè¦æ±‚ï¼š
1. ä½¿ç”¨ä¸­æ–‡ï¼Œæ¸…æ™°çš„æ®µè½ç»“æ„ï¼Œå°½å¯èƒ½ä¿æŒç®€æ´
2. æ›´å¤šä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢å¼ºå¯è¯»æ€§
3. ä¿æŒä¸“ä¸šä¸”å‹å¥½ã€å……æ»¡é¼“åŠ±çš„è¯­æ°”ï¼ˆä¸éœ€è¦å…·ä½“å†™é¼“åŠ±çš„è¯ï¼‰
4. å¯¹äºå…¬å¼å¿…é¡»ç”¨LaTeXæ ¼å¼

è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«åˆé€‚çš„æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰æ ¼å¼åŒ–å…ƒç´ ã€‚`;

  const stream = await client.chat.completions.create({
    model,
    messages: [
      {
        role: 'system',
        content: prompt,
      },
      {
        role: 'user',
        content: 'è¯·ç”Ÿæˆæ€»ç»“æŠ¥å‘Š',
      },
    ],
    temperature: 0.6,
    max_tokens: 4096,
    stream: true,
  });

  let fullContent = '';
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    if (content) {
      fullContent += content;
      onStream?.(fullContent);
    }
  }

  return fullContent;
}

/**
 * ç”Ÿæˆå‹å–„çš„å¤±è´¥å›å¤
 */
export function generateFriendlyFailureMessage(attempts: number): string {
  return `## ğŸ˜Š åˆ†æé‡åˆ°äº†ä¸€äº›å›°éš¾

ç»è¿‡ ${attempts} æ¬¡å°è¯•ï¼Œæˆ‘åœ¨ç†è§£è¿™ä»½ç¬”è®°æ—¶é‡åˆ°äº†ä¸€äº›æŒ‘æˆ˜ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºï¼š

- ğŸ“· å›¾ç‰‡ä¸­çš„å†…å®¹æ¯”è¾ƒå¤æ‚æˆ–ä¸å¤Ÿæ¸…æ™°
- âœï¸ æ‰‹å†™å†…å®¹çš„è¾¨è¯†å­˜åœ¨å›°éš¾
- ğŸ¯ ç¬”è®°çš„é‡ç‚¹æ ‡æ³¨ä¸å¤Ÿæ˜æ˜¾

### ğŸ’¡ å»ºè®®

1. **é‡æ–°æ‹æ‘„**ï¼šå°è¯•åœ¨å…‰çº¿æ›´å¥½çš„ç¯å¢ƒä¸‹é‡æ–°æ‹æ‘„ç¬”è®°
2. **çªå‡ºé‡ç‚¹**ï¼šç”¨æ›´æ˜æ˜¾çš„æ ‡è®°ï¼ˆå¦‚çº¢ç¬”åœˆç”»ï¼‰æ ‡æ³¨éœ€è¦åˆ†æçš„é¢˜ç›®
3. **åˆ†æ‰¹åˆ†æ**ï¼šå¦‚æœç¬”è®°å†…å®¹è¾ƒå¤šï¼Œå¯ä»¥åˆ†æˆå‡ ä»½åˆ†åˆ«æ‹æ‘„åˆ†æ

### ğŸ¤ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œä½ å¯ä»¥ï¼š
- åœ¨ç¬”è®°å†…å®¹ä¸­ç”¨æ–‡å­—è¡¥å……è¯´æ˜å“ªé“é¢˜æœ‰é—®é¢˜
- æä¾›æ›´æ¸…æ™°çš„å›¾ç‰‡
- å°è¯•æè¿°å…·ä½“é‡åˆ°çš„å›°éš¾

ä¸è¦æ°”é¦ï¼å­¦ä¹ è¿‡ç¨‹ä¸­é‡åˆ°å›°éš¾æ˜¯æ­£å¸¸çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ‰¾åˆ°æ›´å¥½çš„æ–¹å¼æ¥å¸®åŠ©ä½ ç†è§£è¿™äº›çŸ¥è¯†ç‚¹ ğŸ’ª`;
}

/**
 * å¤šAgentåˆ†æç»“æœ
 */
export interface MultiAgentAnalysisResult {
  intent: string;
  original: string;
  correction: string;
  summary: string;
  reviewPassed: boolean;
}

/**
 * ä¸»å‡½æ•°ï¼šå¤šAgentåä½œåˆ†æ
 */
export async function multiAgentAnalysis(
  config: {
    baseURL: string;
    apiKey: string;
    model: string;
    provider?: string;
    siteUrl?: string;
    siteName?: string;
  },
  note: Note,
  userMessageContent: any[],
  categoryName: string,
  curveName: string,
  curveIntervals: number[],
  onProgress?: (message: string) => void,
  onStream?: (agentId: string, content: string) => void
): Promise<MultiAgentAnalysisResult> {
  const client = createClient(config);

  try {
    // Step 1: æ„å›¾åˆ†æï¼ˆå¸¦å®¡æŸ¥å’Œé‡è¯•ï¼‰
    onProgress?.('ğŸ¯ å¼€å§‹åˆ†æç”¨æˆ·æ„å›¾...');
    const intentResult = await analyzeIntentWithReview(
      client,
      config.model,
      [...userMessageContent],
      onProgress,
      onStream
    );

    // å¦‚æœç»è¿‡3æ¬¡å°è¯•ä»æœªé€šè¿‡å®¡æŸ¥ï¼Œè¿”å›å‹å–„çš„å¤±è´¥æ¶ˆæ¯
    if (!intentResult.reviewPassed) {
      onProgress?.('âš ï¸ æ„å›¾åˆ†ææœªèƒ½é€šè¿‡å®¡æŸ¥ï¼Œè¿”å›å‹å–„æç¤º');
      const failureMessage = generateFriendlyFailureMessage(intentResult.attempts);
      return {
        intent: intentResult.intent,
        original: failureMessage,
        correction: '',
        summary: '',
        reviewPassed: false,
      };
    }

    // Step 2 & 3: å¹¶è¡Œåˆ†æåŸå§‹è®°å½•å’Œè®¢æ­£ç­”æ¡ˆ
    onProgress?.('ğŸ“ æ­£åœ¨åˆ†æåŸå§‹è®°å½•å’Œè®¢æ­£ç­”æ¡ˆ...');
    const [originalAnalysis, correctionAnalysis] = await Promise.all([
      analyzeOriginalRecord(
        client,
        config.model,
        intentResult.intent,
        userMessageContent,
        (content) => onStream?.('original', content)
      ),
      analyzeCorrection(
        client,
        config.model,
        intentResult.intent,
        userMessageContent,
        (content) => onStream?.('correction', content)
      ),
    ]);

    onProgress?.('ğŸ“Š åŸå§‹è®°å½•å’Œè®¢æ­£åˆ†æå®Œæˆ');

    // Step 4: ç”Ÿæˆæ€»ç»“
    onProgress?.('âœ¨ æ­£åœ¨ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...');
    const summary = await generateSummary(
      client,
      config.model,
      note,
      intentResult.intent,
      originalAnalysis,
      correctionAnalysis,
      categoryName,
      curveName,
      curveIntervals,
      (content) => onStream?.('summary', content)
    );

    onProgress?.('âœ… åˆ†æå®Œæˆï¼');

    // è¿”å›æ¯ä¸ªagentçš„å•ç‹¬ç»“æœ
    return {
      intent: intentResult.intent,
      original: originalAnalysis,
      correction: correctionAnalysis,
      summary: summary,
      reviewPassed: intentResult.reviewPassed,
    };
  } catch (error) {
    console.error('Multi-agent analysis failed:', error);
    throw error;
  }
}
